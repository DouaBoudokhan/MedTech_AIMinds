# AI MINDS - System Architecture

## ğŸ“‹ Architecture Analysis & Recommendations

### âœ… **SOLID FOUNDATION - Your Architecture is Well-Designed**

**Strengths:**

1. âœ… **Clear separation of concerns** (Input â†’ Processing â†’ Storage)
2. âœ… **Dual-collection strategy** (text 384d + visual 512d) - optimal for multimodal
3. âœ… **Intelligent chunking** - handles both short and long documents
4. âœ… **Hierarchical storage** (memory_items â†’ chunks) - efficient for retrieval
5. âœ… **OCR integration** - images searchable both visually AND textually
6. âœ… **Scalable** - Faiss can handle millions of vectors

**Minor Improvements:**

1. âš ï¸ **Audio â†’ CLIP?** - CLIP is for images/text, not needed for audio transcripts
   - **Fix**: Audio â†’ Whisper â†’ transcript â†’ text_collection (no CLIP)
2. âœ… **Neo4j addition** - EXCELLENT idea for relationship mapping
   - Use SQLite for fast lookups, Neo4j for graph traversal
   - Keep entities/categories in SQLite, complex relationships in Neo4j

---

## ğŸ—ï¸ Final Recommended Architecture

### **INPUT PROCESSING PIPELINE**

```
â”œâ”€â†’ Text (email, calendar, clipboard, browser)
â”‚   â””â”€â†’ Length check
â”‚       â”œâ”€ Short (< 512 chars) â†’ Single embedding â†’ text_collection (384d)
â”‚       â””â”€ Long (> 512 chars) â†’ Semantic chunking â†’ Multiple embeddings â†’ text_collection
â”‚
â”œâ”€â†’ Images (screenshots, photos, clipboard images)
â”‚   â”œâ”€â†’ CLIP encoder â†’ visual_collection (512d)
â”‚   â””â”€â†’ OCR (pytesseract/EasyOCR) â†’ text â†’ embedding â†’ text_collection (384d)
â”‚
â”œâ”€â†’ Audio (voice recordings)
â”‚   â””â”€â†’ Whisper (tiny/base) â†’ transcript â†’ chunk if long â†’ text_collection (384d)
â”‚
â””â”€â†’ Documents (PDFs, DOCX)
    â””â”€â†’ Extract text â†’ Semantic chunking â†’ Multiple embeddings â†’ text_collection (384d)
```

### **STORAGE LAYER**

```
â”œâ”€â†’ FAISS (Vector Search)
â”‚   â”œâ”€ text_collection (384d) - Sentence-Transformers multilingual
â”‚   â””â”€ visual_collection (512d) - CLIP ViT-B/32
â”‚
â”œâ”€â†’ SQLite (Metadata & Fast Lookups)
â”‚   â”œâ”€ memory_items (parent documents)
â”‚   â”œâ”€ chunks (text chunks with FK to memory_items)
â”‚   â”œâ”€ entities (people, places, organizations)
â”‚   â””â”€ categories (classifications)
â”‚
â””â”€â†’ Neo4j [OPTIONAL] (Relationship Graph)
    â”œâ”€ Document nodes (mirror memory_items)
    â”œâ”€ Entity nodes (people, places, concepts)
    â””â”€ Relationships (MENTIONED_IN, RELATED_TO, FOLLOWS, PRECEDES)
```

### **WHEN TO USE NEO4J vs SQLite**

**Use SQLite for:**

- âœ… Metadata lookups (by ID, timestamp, source_type)
- âœ… Simple parent-child (memory_item â†’ chunks)
- âœ… Fast existence checks
- âœ… Counting, aggregations

**Use Neo4j for:**

- âœ… "Find all documents related to person X"
- âœ… "What meetings happened before this email?"
- âœ… "Show me the chain of documents about project Y"
- âœ… Network analysis (who collaborates with whom)
- âœ… Temporal graphs (timeline of events)

**Verdict:** Neo4j is **worth it** if you need:

- Temporal reasoning (before/after relationships)
- Entity co-occurrence networks
- Multi-hop queries ("friends of friends")

**Skip Neo4j if:** You only need simple lookups and vector search.

---

## ğŸ“ Project Structure

```
AI minds/
â”‚
â”œâ”€â”€ Data_Layer/                          # Data ingestion & storage
â”‚   â”œâ”€â”€ Data_Collection/                 # Input processors
â”‚   â”‚   â”œâ”€â”€ Browser/
â”‚   â”‚   â”‚   â”œâ”€â”€ browser_ingestion.py    âœ… DONE
â”‚   â”‚   â”‚   â””â”€â”€ test_browser_ingestion.py
â”‚   â”‚   â”œâ”€â”€ Calendar/
â”‚   â”‚   â”‚   â””â”€â”€ calendar_watcher.py     ğŸ“ TODO
â”‚   â”‚   â”œâ”€â”€ Clipboard/
â”‚   â”‚   â”‚   â””â”€â”€ clipboard_watcher.py    ğŸ“ TODO
â”‚   â”‚   â”œâ”€â”€ Email/
â”‚   â”‚   â”‚   â””â”€â”€ email_watcher.py        ğŸ“ TODO
â”‚   â”‚   â”œâ”€â”€ File_System/
â”‚   â”‚   â”‚   â”œâ”€â”€ activity_monitor.py     ğŸ“ TODO
â”‚   â”‚   â”‚   â””â”€â”€ document_extractor.py   ğŸ“ TODO
â”‚   â”‚   â”œâ”€â”€ Screenshots/
â”‚   â”‚   â”‚   â””â”€â”€ screenshot_watcher.py   ğŸ“ TODO
â”‚   â”‚   â””â”€â”€ Audio/
â”‚   â”‚       â””â”€â”€ audio_recorder.py       ğŸ“ TODO
â”‚   â”‚
â”‚   â”œâ”€â”€ Data_Storage/                    # Persistent storage
â”‚   â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â”‚   â”œâ”€â”€ text_index/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ faiss_index.bin
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ id_mapping.pkl
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ metadata.db
â”‚   â”‚   â”‚   â””â”€â”€ visual_index/
â”‚   â”‚   â”‚       â”œâ”€â”€ faiss_index.bin
â”‚   â”‚   â”‚       â”œâ”€â”€ id_mapping.pkl
â”‚   â”‚   â”‚       â””â”€â”€ metadata.db
â”‚   â”‚   â”œâ”€â”€ browser_data_2026_01.json   âœ… DONE
â”‚   â”‚   â””â”€â”€ browser_data_2026_02.json   âœ… DONE
â”‚   â”‚
â”‚   â””â”€â”€ storage_manager.py               âœ… DONE (enhanced)
â”‚
â”œâ”€â”€ Core/                                # Processing engines
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py                    # Sentence-Transformers & CLIP
â”‚   â”œâ”€â”€ text_processor.py                # Chunking, length detection
â”‚   â”œâ”€â”€ image_processor.py               # OCR, CLIP encoding
â”‚   â”œâ”€â”€ audio_processor.py               # Whisper transcription
â”‚   â”œâ”€â”€ document_processor.py            # PDF, DOCX extraction
â”‚   â”œâ”€â”€ entity_extractor.py              # Named entity recognition
â”‚   â”œâ”€â”€ llm_manager.py                   # Local LLM (<4B params)
â”‚   â”œâ”€â”€ rag_engine.py                    # RAG pipeline
â”‚   â””â”€â”€ neo4j_manager.py [OPTIONAL]      # Graph relationships
â”‚
â”œâ”€â”€ API/                                 # User interfaces
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat_interface.py                # Interactive chat
â”‚   â””â”€â”€ web_ui.py [OPTIONAL]             # Gradio/Streamlit UI
â”‚
â”œâ”€â”€ Tests/                               # Testing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_storage.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â””â”€â”€ test_rag.py
â”‚
â”œâ”€â”€ main_daemon.py                       # Background watcher daemon
â”œâ”€â”€ pyproject.toml                       # UV dependencies
â”œâ”€â”€ README.md
â””â”€â”€ ARCHITECTURE.md                      # This file
```

---

## ğŸ”§ Technology Stack

### **Vector Storage**

- **Faiss-CPU** (1.7.4+): L2 for text, IP for visual
- Collections: `text_collection` (384d), `visual_collection` (512d)

### **Embeddings**

- **Text**: `paraphrase-multilingual-MiniLM-L12-v2` (118M, 384d, FR+EN)
- **Vision**: `openai/clip-vit-base-patch32` (151M, 512d)

### **Processing**

- **OCR**: `pytesseract` or `easyocr`
- **Audio**: `openai/whisper-tiny` or `whisper-base` (<1B params)
- **Documents**: `PyPDF2`, `python-docx`
- **NER**: `spacy` (fr_core_news_sm, en_core_web_sm)

### **LLM (Local <4B params)**

- **Phi-2** (2.7B) - Microsoft, best reasoning
- **TinyLlama** (1.1B) - Fast, good quality
- **MobileLLM** (350M-1B) - Ultra-efficient

### **Database**

- **SQLite**: Built-in, metadata
- **Neo4j** [Optional]: Graph relationships

---

## ğŸš€ Implementation Priority

### **Phase 1: Core Storage** âœ… DONE

- [x] Browser ingestion
- [x] Storage manager (Faiss + SQLite)
- [x] Text embeddings
- [x] Visual embeddings
- [x] Chunking system

### **Phase 2: Additional Data Sources** ğŸ“ IN PROGRESS

- [ ] Calendar watcher
- [ ] Clipboard watcher
- [ ] File system monitor
- [ ] Screenshot capture

### **Phase 3: Processing Engines**

- [ ] OCR for images
- [ ] Audio transcription (Whisper)
- [ ] Document extraction (PDF/DOCX)
- [ ] Entity extraction (NER)

### **Phase 4: RAG & LLM**

- [ ] Embeddings manager
- [ ] RAG engine
- [ ] Local LLM integration (Phi-2)
- [ ] Query understanding

### **Phase 5: User Interface**

- [ ] Chat interface (CLI)
- [ ] Background daemon
- [ ] Web UI [Optional]

### **Phase 6: Advanced Features** [Optional]

- [ ] Neo4j integration
- [ ] Temporal reasoning
- [ ] Entity networks
- [ ] Automatic summarization

---

## ğŸ’¡ Recommendations

### **Start Now:**

1. âœ… Keep current Faiss + SQLite setup
2. âœ… Complete 4 other data sources (Calendar, Clipboard, File System, Screenshots)
3. âœ… Implement OCR for images
4. âœ… Build RAG engine with local LLM

### **Add Later (if needed):**

1. Neo4j - Only if you need complex relationship queries
2. Advanced NER - Start with spaCy, upgrade if needed
3. Web UI - CLI first, web later

### **Skip (for now):**

1. Audio processing - Unless voice recording is core use case
2. Real-time video - Out of scope for personal knowledge system
3. Cloud deployment - Challenge requires local operation

---

## ğŸ“Š Expected Performance

### **Storage**

- **Capacity**: 1M+ documents (Faiss handles it)
- **Search latency**: < 100ms for 100k vectors
- **Disk usage**: ~500MB per 100k documents

### **Ingestion Speed**

- Browser: 800+ records/sec
- Images (CLIP): ~10 images/sec (CPU)
- OCR: ~2 images/sec
- Audio (Whisper): ~5x realtime (Whisper-tiny)

### **LLM Inference**

- Phi-2 (2.7B): ~20 tokens/sec (CPU)
- TinyLlama (1.1B): ~50 tokens/sec (CPU)
- Context: 2048 tokens

---

## âœ… Conclusion

**Your architecture is SOLID and well-thought-out.**

Minor tweaks:

1. Remove CLIP from audio pipeline
2. Add Neo4j only if you need graph queries
3. Focus on completing data sources first, then RAG

**Next steps:** Create the folder structure and implement missing components.

---

**Author**: AI MINDS Team  
**Date**: February 14, 2026  
**Status**: Production-Ready Architecture
